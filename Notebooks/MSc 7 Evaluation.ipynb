{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc2dbcb-eba3-4168-ad6f-c8b1ad9b76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70c549bed844850872e84143fb2fa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0eda070eea417bb3970ad7b4c4ef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\peft\\config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kuro_ds = load_dataset('Kurosawama/beam_search_DPO', split = 'train')\n",
    "folio = load_dataset('yale-nlp/FOLIO', split='validation')\n",
    "print(dev)\n",
    "\n",
    "def initialize_model(model_id, llama3):\n",
    "    quant_config = BitsAndBytesConfig(load_in_4bit = True, bnb_4bit_compute_dtype = torch.bfloat16)\n",
    "    gen_config = GenerationConfig.from_pretrained(model_id)\n",
    "    if llama3:\n",
    "        tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')\n",
    "    tokenizer.chat_template = \"\"\"\n",
    "            <|im_start|>system\n",
    "            {SYSTEM}<|im_end|>\n",
    "            <|im_start|>user\n",
    "            {INPUT}<|im_ed|>\n",
    "            <|im_start|>assistant\n",
    "            {OUTPUT}<|im_end|>\n",
    "        \"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config = quant_config, generation_config = gen_config).to(dev)\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    return model, tokenizer\n",
    "\n",
    "#model_id = 'meta-llama/Llama-3.2-1B'\n",
    "#model_id = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "\n",
    "base_model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "align_model_id = 'Kurosawama/Llama-2-7b-DPO-beamsearch-align'\n",
    "\n",
    "base_model, base_tokenizer = initialize_model(base_model_id, False)\n",
    "align_model, align_tokenizer = initialize_model(align_model_id, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bbdef9-7baa-4850-9e6f-b2a6ed0bdd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['story_id', 'premises', 'premises-FOL', 'conclusion', 'conclusion-FOL', 'label', 'example_id'],\n",
       "    num_rows: 203\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15a5480-74eb-4764-bfd3-64ace337bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(prompt, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Genera la respuesta del modelo siguiendo la estrategia de beam_search.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors = 'pt').to(dev)\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 200, num_beams = 3)\n",
    "    ans = tokenizer.batch_decode(outputs, skip_special_tokens = True)[0]\n",
    "    ans = ans[len(prompt):]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80bd49c-ce59-4bbc-98be-77f3fba1515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ex = \"\"\"\n",
    "Given a problem description and a question. The task is to parse the problem and the question into first-order logic formulars.\n",
    "    The grammar of the first-order logic formular is defined as follows:\n",
    "    1) logical conjunction of expr1 and expr2: expr1 ∧ expr2\n",
    "    2) logical disjunction of expr1 and expr2: expr1 ∨ expr2\n",
    "    3) logical exclusive disjunction of expr1 and expr2: expr1 ⊕ expr2\n",
    "    4) logical negation of expr1: ¬expr1\n",
    "    5) expr1 implies expr2: expr1 → expr2\n",
    "    6) expr1 if and only if expr2: expr1 ↔ expr2\n",
    "    7) logical universal quantification: ∀x\n",
    "    8) logical existential quantification: ∃x\n",
    "    --------------\n",
    "    Problem:\n",
    "    All people who regularly drink coffee are dependent on caffeine. People either regularly drink coffee or joke about being addicted to caffeine. No one who jokes about being addicted to caffeine is unaware that caffeine is a drug. Rina is either a student and unaware that caffeine is a drug, or neither a student nor unaware that caffeine is a drug. If Rina is not a person dependent on caffeine and a student, then Rina is either a person dependent on caffeine and a student, or neither a person dependent on caffeine nor a student.\n",
    "    Predicates:\n",
    "    Dependent(x) ::: x is a person dependent on caffeine.\n",
    "    Drinks(x) ::: x regularly drinks coffee.\n",
    "    Jokes(x) ::: x jokes about being addicted to caffeine.\n",
    "    Unaware(x) ::: x is unaware that caffeine is a drug.\n",
    "    Student(x) ::: x is a student.\n",
    "    Premises:\n",
    "    ∀x (Drinks(x) → Dependent(x)) ::: All people who regularly drink coffee are dependent on caffeine.\n",
    "    ∀x (Drinks(x) ⊕ Jokes(x)) ::: People either regularly drink coffee or joke about being addicted to caffeine.\n",
    "    ∀x (Jokes(x) → ¬Unaware(x)) ::: No one who jokes about being addicted to caffeine is unaware that caffeine is a drug. \n",
    "    (Student(rina) ∧ Unaware(rina)) ⊕ ¬(Student(rina) ∨ Unaware(rina)) ::: Rina is either a student and unaware that caffeine is a drug, or neither a student nor unaware that caffeine is a drug. \n",
    "    ¬(Dependent(rina) ∧ Student(rina)) → (Dependent(rina) ∧ Student(rina)) ⊕ ¬(Dependent(rina) ∨ Student(rina)) ::: If Rina is not a person dependent on caffeine and a student, then Rina is either a person dependent on caffeine and a student, or neither a person dependent on caffeine nor a student.\n",
    "    --------------\n",
    "    \n",
    "    Problem:\n",
    "    {}\n",
    "    Predicates:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "782ffe3d-db37-4761-a410-f4955f14898d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People in this club who perform in school talent shows often attend and are very engaged with school events.\n",
      "People in this club either perform in school talent shows often or are inactive and disinterested community members.\n",
      "People in this club who chaperone high school dances are not students who attend the school.\n",
      "All people in this club who are inactive and disinterested members of their community chaperone high school dances.\n",
      "All young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \n",
      "Bonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school. \n",
      " ∀x (InThisClub(x) ∧ PerformOftenIn(x, schoolTalentShow) → Attend(x, schoolEvent) ∧ VeryEngagedWith(x, schoolEvent))\n",
      "∀x (InThisClub(x) → PerformOftenIn(x, schoolTalentShow) ⊕ (InActive(x) ∧ Disinterested(x) ∧ MemberOf(x, community)))\n",
      "∀x (InThisClub(x) ∧ Chaperone(x, highSchoolDance) → ¬(Studen(x) ∧ AttendSchool(x)))\n",
      "∀x (InThisClub(x) ∧ (InActive(x) ∧ Disinterested(x) ∧ MemberOf(x, community)) → Chaperone(x, highSchoolDances))\n",
      "∀x (InThisClub(x) ∧ (YoungChildren(x) ⊕ Teenager(x)) ∧ WishToFurther(x, academicCareer)) → Studen(x) ∧ AttendSchool(x))\n",
      "InThisClub(bonnie) ∧ ¬((Attend(x, schoolEvent) ∧ VeryEngagedWith(bonnie, schoolEvent)) ⊕ (Studen(bonne) ∧ AttendSchool(bonnie)))\n"
     ]
    }
   ],
   "source": [
    "print(folio['premises'][1], '\\n', folio['premises-FOL'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de09f3-7c58-4fde-9712-6d4ab4ffe596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(answer(prompt_ex.format(folio['premises'][1]), base_model, base_tokenizer))\n",
    "print(\"---------------------\")\n",
    "print(answer(prompt_ex.format(folio['premises'][1]), align_model, align_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122fd9e-ff07-4b30-bd4a-fe80497e2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Lo que sigue es una forma de automatizar la evaluación y poder medir valores como Accuracy y demás.\n",
    "# No obstante la evaluación está inconclusa y no se usa para el proyecto de RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e03b6edf-86e3-43d2-8de0-e70a9cdd58e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∀x (DrinkRegularly(x, coffee) → IsDependentOn(x, caffeine)) ∀x (DrinkRegularly(x, coffee)  ∨ (¬WantToBeAddictedTo(x, caffeine))) ∀x (¬WantToBeAddictedTo(x, caffeine) → ¬AwareThatDrug(x, caffeine)) ¬(Student(rina) ⊕  ¬AwareThatDrug(rina, caffeine)) ¬(IsDependentOn(rina, caffeine) ⊕ Student(rina))  \n",
      " --- \n",
      "  Dependent(x) ::: x is a person dependent on caffeine.\n",
      "             Drinks(x) ::: x regularly drinks coffee.\n",
      "             Jokes(x) ::: x jokes about being addicted to caffeine.\n",
      "             Unaware(x) ::: x is unaware that caffeine is a drug.\n",
      "             Student(x) ::: x is a student.\n",
      "             Premises:\n",
      "             ∀x (Drinks(x) → Dependent(x)) ::: All people who regularly drink coffee are dependent on caffeine.\n",
      "             ∀x (Drinks(x) ⊕ Jokes(x)) ::: People who either regularly drink coffee or joke about being addicted to caffeine.\n",
      "             ∀x (Jokes(x) → ¬Unaware(x)) ::: No one who jokes about being addicted to caffeine is unaware that caffeine is a drug. \n",
      "             (Student(rina) ∧ Unaware(rina)) ⊕ ¬(Student(rina) ∨ Unaware(rina)) ::: Rina is either a student and unaware that caffeine is a drug, or neither a student nor unaware\n"
     ]
    }
   ],
   "source": [
    "def get_answer(dataset, ans_num):\n",
    "    \"\"\"\n",
    "    dataset = huggingface dataset \n",
    "    ans_num = int ; Valor de la entrada del dataset que queremos analizar\n",
    "\n",
    "    Nos regresa las respuestas del modelo filtradas. \n",
    "    \"\"\"\n",
    "    chosen = dataset['chosen'][ans_num][1]['content']\n",
    "    rejected = dataset['rejected'][ans_num][1]['content']\n",
    "    return chosen, rejected\n",
    "\n",
    "cho1, rej1 = get_answer(kuro_ds, 0)\n",
    "print(cho1, '\\n', '---', '\\n', rej1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e17a3a97-c2ff-42a3-9062-a4d2d5135c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'∀x (DrinkRegularly(x, coffee) → IsDependentOn(x, caffeine)) ∀x (DrinkRegularly(x, coffee)  ∨ (¬WantToBeAddictedTo(x, caffeine))) ∀x (¬WantToBeAddictedTo(x, caffeine) → ¬AwareThatDrug(x, caffeine)) ¬(Student(rina) ⊕  ¬AwareThatDrug(rina, caffeine)) ¬(IsDependentOn(rina, caffeine) ⊕ Student(rina)) '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cho1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8fea72-2042-4326-af7b-d692500fb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '(DrinkRegularly(x, coffee) → IsDependentOn(x, caffeine)) ',\n",
       " '(DrinkRegularly(x, coffee)  ∨ (¬WantToBeAddictedTo(x, caffeine))) ',\n",
       " '(¬WantToBeAddictedTo(x, caffeine) → ¬AwareThatDrug(x, caffeine)) ¬(Student(rina) ⊕  ¬AwareThatDrug(rina, caffeine)) ¬(IsDependentOn(rina, caffeine) ⊕ Student(rina)) ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '∀x|∃x'\n",
    "cho1.split('∀x ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82011c54-7dbc-4b79-8251-8b1af036adf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' (DrinkRegularly(x, coffee) → IsDependentOn(x, caffeine)) ',\n",
       " ' (DrinkRegularly(x, coffee)  ∨ (¬WantToBeAddictedTo(x, caffeine))) ',\n",
       " ' (¬WantToBeAddictedTo(x, caffeine) → ¬AwareThatDrug(x, caffeine)) ',\n",
       " 'Student(rina) ⊕  ¬AwareThatDrug(rina, caffeine)) ',\n",
       " 'IsDependentOn(rina, caffeine) ⊕ Student(rina)) ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('∀x|∃x|¬\\(', cho1) # Casi pero no nos regesa la ER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a17a6-41d2-4417-a935-90b25836b9f2",
   "metadata": {},
   "source": [
    "**VER QUÉ VERGAS VAMOS A HACER PARA LA EVALUACIÓN Y LA SEPARACIÓN DE PREMISAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeeec4c-2cc5-4120-ac91-8730a9191578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
